# Docker compose file covering DataHub's default configuration, which is to run all containers on a single host.

# Please see the README.md for instructions as to how to use and customize.

# NOTE: This file will cannot build! No dockerfiles are set. See the README.md in this directory.
---
version: '3.9'
services:
  datahub-frontend-react:
    container_name: datahub-frontend-react
    hostname: datahub-frontend-react
    image: ${DATAHUB_FRONTEND_IMAGE:-linkedin/datahub-frontend-react}:debug
    ports:
      - ${DATAHUB_MAPPED_FRONTEND_PORT:-9002}:9002
    build:
      context: ../
      dockerfile: docker/datahub-frontend/Dockerfile
      args:
        APP_ENV: dev
    env_file: datahub-frontend/env/docker.env
    #    depends_on:
    #  datahub-gms:
    #    condition: service_healthy
    volumes:
      - ${HOME}/.datahub/plugins:/etc/datahub/plugins

  datahub-actions:
    container_name: datahub-actions
    hostname: actions
    image: ${DATAHUB_ACTIONS_IMAGE:-acryldata/datahub-actions}:${ACTIONS_VERSION:-head}
    env_file: datahub-actions/env/docker.env
    environment:
      - ACTIONS_EXTRA_PACKAGES=${ACTIONS_EXTRA_PACKAGES:-}
      - ACTIONS_CONFIG=${ACTIONS_CONFIG:-}
    depends_on:
      datahub-gms:
        condition: service_healthy
  datahub-gms:
    image: linkedin/datahub-gms:debug
    ports:
      - ${DATAHUB_MAPPED_GMS_DEBUG_PORT:-5001}:5001
      - ${DATAHUB_MAPPED_GMS_PORT:-8080}:8080
    build:
      context: datahub-gms
      dockerfile: Dockerfile
      args:
        APP_ENV: dev
    env_file: datahub-gms/env/docker-without-neo4j.env
    environment:
      - SKIP_ELASTICSEARCH_CHECK=true
      - DATAHUB_SERVER_TYPE=${DATAHUB_SERVER_TYPE:-dev}
      - DATAHUB_TELEMETRY_ENABLED=${DATAHUB_TELEMETRY_ENABLED:-true}
      - METADATA_SERVICE_AUTH_ENABLED=true
      - JAVA_TOOL_OPTIONS=-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=*:5001
      - BOOTSTRAP_SYSTEM_UPDATE_WAIT_FOR_SYSTEM_UPDATE=false
      - SEARCH_SERVICE_ENABLE_CACHE=false
      - LINEAGE_SEARCH_CACHE_ENABLED=false
      - SHOW_BROWSE_V2=true
    volumes:
      - ./datahub-gms/start.sh:/datahub/datahub-gms/scripts/start.sh
      - ./datahub-gms/jetty.xml:/datahub/datahub-gms/scripts/jetty.xml
      - ./monitoring/client-prometheus-config.yaml:/datahub/datahub-gms/scripts/prometheus-config.yaml
      - ../metadata-models/src/main/resources/:/datahub/datahub-gms/resources
      - ../metadata-service/war/build/libs/:/datahub/datahub-gms/bin
      - ${HOME}/.datahub/plugins:/etc/datahub/plugins
    depends_on:
      datahub-upgrade:
        condition: service_completed_successfully
  datahub-upgrade:
    container_name: datahub-upgrade
    hostname: datahub-upgrade
    image: ${DATAHUB_UPGRADE_IMAGE:-acryldata/datahub-upgrade}:debug
    command:
      - -u
      - SystemUpdate
    build:
      context: datahub-upgrade
      dockerfile: Dockerfile
    env_file: datahub-upgrade/env/docker-without-neo4j.env
    depends_on:
      mysql-setup:
        condition: service_completed_successfully
      elasticsearch-setup:
        condition: service_completed_successfully
      kafka-setup:
        condition: service_completed_successfully
    labels:
      datahub_setup_job: true
  # This "container" is a workaround to pre-create search indices
  elasticsearch-setup:
    image: linkedin/datahub-elasticsearch-setup:debug
    build:
      context: elasticsearch-setup
      dockerfile: Dockerfile
      args:
        APP_ENV: dev
    env_file: elasticsearch-setup/env/docker.env
    volumes:
      - ./elasticsearch-setup/create-indices.sh:/create-indices.sh
      - ../metadata-service/restli-servlet-impl/src/main/resources/index/:/index
    labels:
      datahub_setup_job: true
  mysql-setup:
    container_name: mysql-setup
    hostname: mysql-setup
    image: ${DATAHUB_MYSQL_SETUP_IMAGE:-acryldata/datahub-mysql-setup}:debug
    build:
      context: ../
      dockerfile: docker/mysql-setup/Dockerfile
    env_file: mysql-setup/env/docker.env
    labels:
      datahub_setup_job: true
  kafka-setup:
    container_name: kafka-setup
    hostname: kafka-setup
    image: ${DATAHUB_KAFKA_SETUP_IMAGE:-linkedin/datahub-kafka-setup}:head
    build:
      dockerfile: ./docker/kafka-setup/Dockerfile
      context: ../
    env_file: kafka-setup/env/docker.env
    depends_on:
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    labels:
      datahub_setup_job: true
  schema-registry:
    container_name: schema-registry
    hostname: schema-registry
    image: confluentinc/cp-schema-registry:7.4.0
    ports:
      - ${DATAHUB_MAPPED_SCHEMA_REGISTRY_PORT:-8081}:8081
    env_file: schema-registry/env/docker.env
    healthcheck:
      test: nc -z schema-registry ${DATAHUB_MAPPED_SCHEMA_REGISTRY_PORT:-8081}
      start_period: 60s
      interval: 1s
      retries: 3
      timeout: 5s
    depends_on:
      broker:
        condition: service_healthy
  broker:
    container_name: broker
    hostname: broker
    image: confluentinc/cp-kafka:7.4.0
    ports:
      - ${DATAHUB_MAPPED_KAFKA_BROKER_PORT:-9092}:9092
    env_file: broker/env/docker.env
    healthcheck:
      test: nc -z broker $${DATAHUB_MAPPED_KAFKA_BROKER_PORT:-9092}
      start_period: 60s
      interval: 1s
      retries: 5
      timeout: 5s
    depends_on:
      zookeeper:
        condition: service_healthy
    volumes:
      - broker:/var/lib/kafka/data/
  zookeeper:
    container_name: zookeeper
    hostname: zookeeper
    image: confluentinc/cp-zookeeper:7.4.0
    ports:
      - ${DATAHUB_MAPPED_ZK_PORT:-2181}:2181
    env_file: zookeeper/env/docker.env
    healthcheck:
      test: echo srvr | nc zookeeper $${DATAHUB_MAPPED_ZK_PORT:-2181}
      start_period: 30s
      interval: 5s
      retries: 3
      timeout: 5s
    volumes:
      - zkdata:/var/lib/zookeeper
networks:
  default:
    name: datahub_network
volumes:
  esdata:
  broker:
  zkdata: